{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST 실습\n",
        "\n",
        "이번에는 28x28 흑백 손글씨 이미지를 보고 0~9 사이의 숫자 중 어떤 숫자를 쓴 것인지 예측하는 문제를 실습합니다.\n",
        "이번 실습에서는 GPU를 활용할 것이기 때문에, 이전 챕터에서 Colab에서 GPU를 설정하는 방법을 따라해주시길 바랍니다.\n",
        "\n",
        "GPU를 설정했으면 library들을 import합니다."
      ],
      "metadata": {
        "id": "OPJenlrhihrh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6lXVfXoDtoQh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음은 dataset을 준비합니다. 손글씨 dataset은 MNIST라는 유명한 dataset이 있습니다. 이 dataset은 `torchvision`에서 제공하고 있으며, 다음과 같이 다운로드 받을 수 있습니다."
      ],
      "metadata": {
        "id": "pF-1zQvmiult"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "KAYlqPaRt6ti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c0de9f-d7a4-4aa9-8f92-aa7541223a9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 59.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.84MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 15.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.93MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST는 손글씨 사진과 어떤 숫자를 의미하는지에 대한 label의 pair들로 구성되어있습니다.\n",
        "이 때, 우리는 PyTorch model을 사용할 것이기 때문에 손글씨 사진들을 모두 tensor로 변환해야합니다.\n",
        "이러한 부가적인 변환들은 `torchvision.transforms`에서 제공하고 있으며, `torchvision.datasets.MNIST`에서 `transform` 인자로 받을 수 있습니다.\n",
        "우리는 단순히 사진을 tensor로 바꾸고 싶기 때문에 `transforms.ToTensor()` transformation을 넘겨줍니다.\n",
        "\n",
        "다음은 전체 data의 개수와 첫 번째 data를 출력한 결과입니다."
      ],
      "metadata": {
        "id": "p-GqH7_ZjVMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "print(len(trainset))\n",
        "print(trainset[0][0].shape, trainset[0][1])\n",
        "plt.imshow(trainset[0][0][0], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "Zsp3sHmojyhT",
        "outputId": "4aeba24e-7419-405b-fb95-7b6e366af1fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "torch.Size([1, 28, 28]) 5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78d73509e210>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫 번째 출력결과를 통해 우리는 6만장의 손글씨 data가 있는 것을 알 수 있습니다.\n",
        "그리고 두 번째 출력결과를 통해 첫 번째 data의 shape은 (1, 28, 28)이고 5라는 숫자를 쓴 사진이라는 것을 알 수 있습니다.\n",
        "마지막으로 `plt.imshow`를 통해 visualize 했을 때 5라는 숫자가 나오는 것을 알 수 있습니다.\n",
        "\n",
        "다음은 SGD를 위해 dataset을 여러 개의 batch로 나누는 과정을 PyTorch로 구현한 모습입니다."
      ],
      "metadata": {
        "id": "udm8wDBsi301"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "UxKu3kA2i5WH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch에서는 `DataLoader`가 dataset을 인자로 받아 batch로 나눠줍니다.\n",
        "부가적으로 `batch_size`라는 인자를 통해 batch size를 받고 있으며, `shuffle`이라는 인자를 통해 data들을 섞을지 결정해줍니다.\n",
        "우리는 SGD가 완전 랜덤으로 batch를 구성해야 잘 동작하는 것을 알고 있기 때문에 `shuffle`에 `True`를 넘겨주고 있습니다.\n",
        "\n",
        "다음은 첫 번째 batch를 출력한 모습입니다."
      ],
      "metadata": {
        "id": "z4Qyrm4WlzWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "print(images.shape, labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Hd7XxyAvVNz",
        "outputId": "4da720f9-48fd-466d-e36e-e14aa6ba87d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`images`는 첫 번째 batch의 image들이고 `labels`는 첫 번째 batch의 label들입니다.\n",
        "위에서 batch size를 64로 설정했기 때문에 총 64개의 image와 label들이 있어야 합니다.\n",
        "실제 shape 출력 결과를 보면 그렇다는 것을 알 수 있습니다.\n",
        "\n",
        "다음은 (n, 1, 28, 28) shape의 image를 입력받아 0~9 사이의 정수 하나를 출력하는 3-layer MLP를 구현합니다."
      ],
      "metadata": {
        "id": "h0ZY5mDimRUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, input_dim, n_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer1 = nn.Linear(input_dim, n_dim)\n",
        "    self.layer2 = nn.Linear(n_dim, n_dim)\n",
        "    self.layer3 = nn.Linear(n_dim, 1)\n",
        "\n",
        "    self.act = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "    x = self.act(self.layer1(x))\n",
        "    x = self.act(self.layer2(x))\n",
        "    x = self.act(self.layer3(x))\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "model = Model(28 * 28 * 1, 1024)"
      ],
      "metadata": {
        "id": "OLOA-ZGTuVVG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전의 2-layer MLP와 유사한 형태임을 알 수 있습니다.\n",
        "여기서 특이사항은 `forward`의 첫 번째 줄에 `torch.flatten`을 사용한다는 것입니다.\n",
        "`Linear`는 이전에도 봤다시피 (n, d) 형태의 shape을 입력받습니다.\n",
        "이미지는 (n, 1, 28, 28)이기 때문에 (n, 1 * 28 * 28)로 shape을 변환해야 선형 함수에 입력으로 주어줄 수 있게 됩니다.\n",
        "이 역할을 수행하는 것이 바로 `torch.flatten`입니다.\n",
        "우리는 첫 번째 shape인 n을 보존할 것이기 때문에 flatten할 차원은 `start_dim=1`로 넘겨주게 됩니다.\n",
        "\n",
        "다음은 gradient descent를 수행해줄 optimizer를 구현하는 모습입니다."
      ],
      "metadata": {
        "id": "tag1rNcwmnAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD\n",
        "\n",
        "lr = 0.001\n",
        "model = model.to('cuda')\n",
        "\n",
        "optimizer = SGD(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "ypS0TcOlvBhZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전 코드와 거의 똑같습니다. 다른 점은 `model.to('cuda')` 코드를 통해 우리가 구현한 model을 GPU로 옮긴 것입니다.\n",
        "MNIST 부터는 모델과 data가 커지면서 훨씬 많은 행렬 연산이 이루어지기 때문에 GPU를 활용하는 것이 빠릅니다.\n",
        "\n",
        "다음은 model을 MNIST에 학습하는 코드입니다."
      ],
      "metadata": {
        "id": "5PooeOKMnRfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  total_loss = 0.\n",
        "  for data in trainloader:\n",
        "    model.zero_grad()\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "\n",
        "    preds = model(inputs)\n",
        "    loss = (preds[:, 0] - labels).pow(2).mean()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch {epoch:3d} | Loss: {total_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TryX1hewvNiB",
        "outputId": "71ec8b04-a286-4539-e54f-bb402ca1abc0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0 | Loss: 4592.981165885925\n",
            "Epoch   1 | Loss: 2509.201806306839\n",
            "Epoch   2 | Loss: 1787.3266285061836\n",
            "Epoch   3 | Loss: 1399.0115184783936\n",
            "Epoch   4 | Loss: 1178.7243893742561\n",
            "Epoch   5 | Loss: 1041.094489067793\n",
            "Epoch   6 | Loss: 945.3465427458286\n",
            "Epoch   7 | Loss: 875.3829755485058\n",
            "Epoch   8 | Loss: 818.8983617722988\n",
            "Epoch   9 | Loss: 771.9835598170757\n",
            "Epoch  10 | Loss: 728.1790100336075\n",
            "Epoch  11 | Loss: 694.7963078916073\n",
            "Epoch  12 | Loss: 660.9991959035397\n",
            "Epoch  13 | Loss: 634.2663460075855\n",
            "Epoch  14 | Loss: 610.0653198808432\n",
            "Epoch  15 | Loss: 585.0731422901154\n",
            "Epoch  16 | Loss: 564.5927057862282\n",
            "Epoch  17 | Loss: 544.6631497442722\n",
            "Epoch  18 | Loss: 525.2609236836433\n",
            "Epoch  19 | Loss: 505.51896642148495\n",
            "Epoch  20 | Loss: 491.3540384322405\n",
            "Epoch  21 | Loss: 477.9222260862589\n",
            "Epoch  22 | Loss: 462.0644992887974\n",
            "Epoch  23 | Loss: 449.0516777038574\n",
            "Epoch  24 | Loss: 437.57233779132366\n",
            "Epoch  25 | Loss: 425.5715845823288\n",
            "Epoch  26 | Loss: 412.6004212424159\n",
            "Epoch  27 | Loss: 400.0534350499511\n",
            "Epoch  28 | Loss: 388.398758739233\n",
            "Epoch  29 | Loss: 381.67610981315374\n",
            "Epoch  30 | Loss: 370.031166985631\n",
            "Epoch  31 | Loss: 361.069419965148\n",
            "Epoch  32 | Loss: 354.40939731895924\n",
            "Epoch  33 | Loss: 345.069480240345\n",
            "Epoch  34 | Loss: 337.4594908580184\n",
            "Epoch  35 | Loss: 325.7578854486346\n",
            "Epoch  36 | Loss: 325.75414134562016\n",
            "Epoch  37 | Loss: 315.9244097098708\n",
            "Epoch  38 | Loss: 306.35664823651314\n",
            "Epoch  39 | Loss: 305.3724647834897\n",
            "Epoch  40 | Loss: 297.0944343805313\n",
            "Epoch  41 | Loss: 294.7116658911109\n",
            "Epoch  42 | Loss: 282.01752630621195\n",
            "Epoch  43 | Loss: 274.06131210923195\n",
            "Epoch  44 | Loss: 270.88749563694\n",
            "Epoch  45 | Loss: 264.0763680189848\n",
            "Epoch  46 | Loss: 261.1846969872713\n",
            "Epoch  47 | Loss: 261.534065335989\n",
            "Epoch  48 | Loss: 250.08885538578033\n",
            "Epoch  49 | Loss: 247.19959462434053\n",
            "Epoch  50 | Loss: 239.02103734016418\n",
            "Epoch  51 | Loss: 240.3338061645627\n",
            "Epoch  52 | Loss: 233.55423444509506\n",
            "Epoch  53 | Loss: 227.64331124722958\n",
            "Epoch  54 | Loss: 224.2450755238533\n",
            "Epoch  55 | Loss: 216.66703002154827\n",
            "Epoch  56 | Loss: 218.2786326110363\n",
            "Epoch  57 | Loss: 216.5072169303894\n",
            "Epoch  58 | Loss: 205.722798705101\n",
            "Epoch  59 | Loss: 209.37958592921495\n",
            "Epoch  60 | Loss: 201.15237252041698\n",
            "Epoch  61 | Loss: 198.83073408901691\n",
            "Epoch  62 | Loss: 197.73986086249352\n",
            "Epoch  63 | Loss: 189.17721172049642\n",
            "Epoch  64 | Loss: 191.99084647744894\n",
            "Epoch  65 | Loss: 191.88551095873117\n",
            "Epoch  66 | Loss: 181.47950252518058\n",
            "Epoch  67 | Loss: 181.4269801825285\n",
            "Epoch  68 | Loss: 180.33644327893853\n",
            "Epoch  69 | Loss: 171.5434909425676\n",
            "Epoch  70 | Loss: 170.7704346626997\n",
            "Epoch  71 | Loss: 164.51474441215396\n",
            "Epoch  72 | Loss: 168.6398333646357\n",
            "Epoch  73 | Loss: 165.53252070769668\n",
            "Epoch  74 | Loss: 159.0244663581252\n",
            "Epoch  75 | Loss: 154.47658371552825\n",
            "Epoch  76 | Loss: 151.71666902676225\n",
            "Epoch  77 | Loss: 149.5411223359406\n",
            "Epoch  78 | Loss: 160.3371403515339\n",
            "Epoch  79 | Loss: 143.43974383175373\n",
            "Epoch  80 | Loss: 143.228086091578\n",
            "Epoch  81 | Loss: 143.1443230547011\n",
            "Epoch  82 | Loss: 141.5887159742415\n",
            "Epoch  83 | Loss: 140.85101825371385\n",
            "Epoch  84 | Loss: 140.174331266433\n",
            "Epoch  85 | Loss: 136.3810273334384\n",
            "Epoch  86 | Loss: 131.9238124154508\n",
            "Epoch  87 | Loss: 130.09932442381978\n",
            "Epoch  88 | Loss: 134.96645594760776\n",
            "Epoch  89 | Loss: 129.14943308010697\n",
            "Epoch  90 | Loss: 118.0034096725285\n",
            "Epoch  91 | Loss: 123.80646520480514\n",
            "Epoch  92 | Loss: 131.83959731832147\n",
            "Epoch  93 | Loss: 116.87103329598904\n",
            "Epoch  94 | Loss: 117.05500338971615\n",
            "Epoch  95 | Loss: 114.94237088412046\n",
            "Epoch  96 | Loss: 114.94979755580425\n",
            "Epoch  97 | Loss: 118.15139215439558\n",
            "Epoch  98 | Loss: 120.20321264863014\n",
            "Epoch  99 | Loss: 108.33803782239556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "출력 결과를 보면 잘 수렴하는 것을 볼 수 있습니다.\n",
        "이전 구현과 다른 점은 다음 두 가지입니다.\n",
        "- `for data in trainloader`를 통해 batch들을 iterate하면서 model을 학습합니다.\n",
        "- `inputs, labels = inputs.to('cuda'), labels.to('cuda')`를 통해 model의 입력으로 들어가는 tensor들을 GPU로 보냅니다.\n",
        "\n",
        "마지막으로 첫 번째 data에 대한 예측 결과를 살펴봅시다."
      ],
      "metadata": {
        "id": "YRDcptrqniX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "\n",
        "x = trainset[idx][0][None]  # (1, 1, 28, 28)\n",
        "x = x.to('cuda')\n",
        "\n",
        "print(model(x))\n",
        "print(trainset[idx][1])"
      ],
      "metadata": {
        "id": "Zct0ssSKwjt1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49fec9cf-ec2e-4bbb-ce3d-ebd8dbfc67e1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.8415]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 idx를 조정하여 다른 data에 대한 출력 결과도 볼 수 있습니다.\n",
        "예측 결과를 보시면 아직 성능이 그렇게 좋지 않은 것을 알 수 있습니다."
      ],
      "metadata": {
        "id": "qzgSOrMsoZ2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [1주차] 기본과제 - MNIST를 분류 모델로 학습하기\n",
        "\n",
        "# Step 1: Test 데이터셋 생성"
      ],
      "metadata": {
        "id": "vwuufavSDx7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "d6M4SpWQoML9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 확인"
      ],
      "metadata": {
        "id": "zRGSlcpXHKat"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(testset))\n",
        "images, labels = next(iter(testloader))\n",
        "print(images.shape, labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_AJjZODHWTb",
        "outputId": "8768b83f-2fa1-47aa-f032-bd739a138af4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2. CrossEntropyLoss로 바꾸기"
      ],
      "metadata": {
        "id": "Bmah4TZJHnw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, input_dim, n_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer1 = nn.Linear(input_dim, n_dim)\n",
        "    self.layer2 = nn.Linear(n_dim, n_dim)\n",
        "    self.layer3 = nn.Linear(n_dim, 10)\n",
        "\n",
        "    self.act = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "    x = self.act(self.layer1(x))\n",
        "    x = self.act(self.layer2(x))\n",
        "    x = self.act(self.layer3(x))\n",
        "\n",
        "    return x\n",
        "\n",
        "# 손실 함수 정의 변경\n",
        "loss_fn = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "KjOCLA-yHmYr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD\n",
        "\n",
        "lr = 0.001\n",
        "model = model.to('cuda')\n",
        "optimizer = SGD(model.parameters(), lr=lr)\n",
        "\n",
        "n_epochs = 100\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    total_loss = 0.\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        labels = labels.long()\n",
        "\n",
        "        model.zero_grad()\n",
        "        preds = model(inputs)\n",
        "\n",
        "        loss = loss_fn(preds, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch:3d} | Loss: {total_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ETLDZvOHWty",
        "outputId": "49ad4d69-cf0a-4ef9-a585-04eafc4a7472"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0 | Loss: 2132.6349251270294\n",
            "Epoch   1 | Loss: 2070.767764568329\n",
            "Epoch   2 | Loss: 1972.1258002519608\n",
            "Epoch   3 | Loss: 1811.897225022316\n",
            "Epoch   4 | Loss: 1580.9059919118881\n",
            "Epoch   5 | Loss: 1322.4909065961838\n",
            "Epoch   6 | Loss: 1111.6843964457512\n",
            "Epoch   7 | Loss: 969.710176050663\n",
            "Epoch   8 | Loss: 874.8815505504608\n",
            "Epoch   9 | Loss: 807.4331187307835\n",
            "Epoch  10 | Loss: 756.6156152486801\n",
            "Epoch  11 | Loss: 716.7554951012135\n",
            "Epoch  12 | Loss: 684.4822281002998\n",
            "Epoch  13 | Loss: 657.8771381378174\n",
            "Epoch  14 | Loss: 635.5138416588306\n",
            "Epoch  15 | Loss: 616.6234413683414\n",
            "Epoch  16 | Loss: 600.3421022891998\n",
            "Epoch  17 | Loss: 586.1884736716747\n",
            "Epoch  18 | Loss: 573.8467253595591\n",
            "Epoch  19 | Loss: 563.0659447014332\n",
            "Epoch  20 | Loss: 553.2857710421085\n",
            "Epoch  21 | Loss: 544.8480432629585\n",
            "Epoch  22 | Loss: 537.2745437175035\n",
            "Epoch  23 | Loss: 530.0941373705864\n",
            "Epoch  24 | Loss: 523.8025459647179\n",
            "Epoch  25 | Loss: 518.0930767506361\n",
            "Epoch  26 | Loss: 512.8923438936472\n",
            "Epoch  27 | Loss: 508.1026113331318\n",
            "Epoch  28 | Loss: 503.31726594269276\n",
            "Epoch  29 | Loss: 499.2425685226917\n",
            "Epoch  30 | Loss: 495.3381725400686\n",
            "Epoch  31 | Loss: 491.52027006447315\n",
            "Epoch  32 | Loss: 488.11677245795727\n",
            "Epoch  33 | Loss: 484.98020258545876\n",
            "Epoch  34 | Loss: 481.669655457139\n",
            "Epoch  35 | Loss: 478.8100379705429\n",
            "Epoch  36 | Loss: 476.0241561830044\n",
            "Epoch  37 | Loss: 473.52862879633904\n",
            "Epoch  38 | Loss: 470.79192392528057\n",
            "Epoch  39 | Loss: 468.399267449975\n",
            "Epoch  40 | Loss: 466.1127694696188\n",
            "Epoch  41 | Loss: 463.86842043697834\n",
            "Epoch  42 | Loss: 461.84519527852535\n",
            "Epoch  43 | Loss: 459.76060676574707\n",
            "Epoch  44 | Loss: 457.6608671993017\n",
            "Epoch  45 | Loss: 455.54720313847065\n",
            "Epoch  46 | Loss: 453.78264740109444\n",
            "Epoch  47 | Loss: 451.8638527840376\n",
            "Epoch  48 | Loss: 450.1254946887493\n",
            "Epoch  49 | Loss: 448.23749059438705\n",
            "Epoch  50 | Loss: 446.44889169186354\n",
            "Epoch  51 | Loss: 444.7950037419796\n",
            "Epoch  52 | Loss: 443.1840256303549\n",
            "Epoch  53 | Loss: 441.77295573055744\n",
            "Epoch  54 | Loss: 440.08370238542557\n",
            "Epoch  55 | Loss: 438.4305361658335\n",
            "Epoch  56 | Loss: 436.87434738874435\n",
            "Epoch  57 | Loss: 435.5778480246663\n",
            "Epoch  58 | Loss: 433.80248941481113\n",
            "Epoch  59 | Loss: 432.4589905291796\n",
            "Epoch  60 | Loss: 430.997476503253\n",
            "Epoch  61 | Loss: 429.5314038321376\n",
            "Epoch  62 | Loss: 428.2501208484173\n",
            "Epoch  63 | Loss: 426.7502220645547\n",
            "Epoch  64 | Loss: 425.56951531767845\n",
            "Epoch  65 | Loss: 424.11424292623997\n",
            "Epoch  66 | Loss: 422.8564215451479\n",
            "Epoch  67 | Loss: 421.5918211340904\n",
            "Epoch  68 | Loss: 420.3378513008356\n",
            "Epoch  69 | Loss: 418.99176974594593\n",
            "Epoch  70 | Loss: 417.7803069204092\n",
            "Epoch  71 | Loss: 416.35565223544836\n",
            "Epoch  72 | Loss: 415.2173049300909\n",
            "Epoch  73 | Loss: 413.8610083833337\n",
            "Epoch  74 | Loss: 412.92807242274284\n",
            "Epoch  75 | Loss: 411.6044552475214\n",
            "Epoch  76 | Loss: 410.4956214427948\n",
            "Epoch  77 | Loss: 409.2088824957609\n",
            "Epoch  78 | Loss: 408.0483711063862\n",
            "Epoch  79 | Loss: 406.80251032859087\n",
            "Epoch  80 | Loss: 405.77185955643654\n",
            "Epoch  81 | Loss: 404.6399499475956\n",
            "Epoch  82 | Loss: 403.44395449757576\n",
            "Epoch  83 | Loss: 402.3474006280303\n",
            "Epoch  84 | Loss: 401.1992412060499\n",
            "Epoch  85 | Loss: 400.0609108507633\n",
            "Epoch  86 | Loss: 399.0794839709997\n",
            "Epoch  87 | Loss: 397.97243298590183\n",
            "Epoch  88 | Loss: 396.9295935481787\n",
            "Epoch  89 | Loss: 395.5944314301014\n",
            "Epoch  90 | Loss: 394.6671285033226\n",
            "Epoch  91 | Loss: 393.6522377207875\n",
            "Epoch  92 | Loss: 392.6386257261038\n",
            "Epoch  93 | Loss: 391.6486017368734\n",
            "Epoch  94 | Loss: 390.48064310848713\n",
            "Epoch  95 | Loss: 389.4888876006007\n",
            "Epoch  96 | Loss: 388.5770962834358\n",
            "Epoch  97 | Loss: 387.4546281695366\n",
            "Epoch  98 | Loss: 386.4252953007817\n",
            "Epoch  99 | Loss: 385.4540748670697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, dataloader):\n",
        "    cnt = 0\n",
        "    acc = 0\n",
        "\n",
        "    model.eval()  # 평가 모드로 설정 (일관된 추론 결과를 보장)\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "            preds = model(inputs)\n",
        "            preds = torch.argmax(preds, dim=-1)\n",
        "\n",
        "            cnt += labels.shape[0]\n",
        "            acc += (labels == preds).sum().item()\n",
        "\n",
        "    model.train()  # 다시 학습 모드로 복귀\n",
        "    return acc / cnt"
      ],
      "metadata": {
        "id": "Xkixjd3pJ_Ls"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_acc(train_accs, test_accs, label1='train', label2='test'):\n",
        "    x = np.arange(len(train_accs))\n",
        "    plt.plot(x, train_accs, label=label1)\n",
        "    plt.plot(x, test_accs, label=label2)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Train vs Test Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aCRx3zFLMKkA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "train_accs = []\n",
        "test_accs = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    total_loss = 0.\n",
        "\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "        labels = labels.long()\n",
        "\n",
        "        model.zero_grad()\n",
        "        preds = model(inputs)\n",
        "        loss = loss_fn(preds, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # 정확도 측정\n",
        "    train_acc = accuracy(model, trainloader)\n",
        "    test_acc = accuracy(model, testloader)\n",
        "    train_accs.append(train_acc)\n",
        "    test_accs.append(test_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch:3d} | Loss: {total_loss:.4f} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaCLNwX0MXLB",
        "outputId": "635306a8-37cd-4019-b8ef-f9e9166f3b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0 | Loss: 384.4446 | Train Acc: 0.8631 | Test Acc: 0.8650\n",
            "Epoch   1 | Loss: 383.6011 | Train Acc: 0.8635 | Test Acc: 0.8647\n",
            "Epoch   2 | Loss: 382.4135 | Train Acc: 0.8638 | Test Acc: 0.8643\n",
            "Epoch   3 | Loss: 381.7182 | Train Acc: 0.8640 | Test Acc: 0.8651\n",
            "Epoch   4 | Loss: 380.6257 | Train Acc: 0.8643 | Test Acc: 0.8658\n",
            "Epoch   5 | Loss: 379.7407 | Train Acc: 0.8648 | Test Acc: 0.8656\n",
            "Epoch   6 | Loss: 378.7234 | Train Acc: 0.8648 | Test Acc: 0.8665\n",
            "Epoch   7 | Loss: 377.6666 | Train Acc: 0.8649 | Test Acc: 0.8662\n",
            "Epoch   8 | Loss: 376.7655 | Train Acc: 0.8652 | Test Acc: 0.8658\n",
            "Epoch   9 | Loss: 376.0518 | Train Acc: 0.8656 | Test Acc: 0.8663\n",
            "Epoch  10 | Loss: 375.1139 | Train Acc: 0.8657 | Test Acc: 0.8662\n",
            "Epoch  11 | Loss: 373.8093 | Train Acc: 0.8660 | Test Acc: 0.8660\n",
            "Epoch  12 | Loss: 372.9824 | Train Acc: 0.8661 | Test Acc: 0.8665\n",
            "Epoch  13 | Loss: 372.3382 | Train Acc: 0.8663 | Test Acc: 0.8659\n",
            "Epoch  14 | Loss: 371.4092 | Train Acc: 0.8666 | Test Acc: 0.8668\n",
            "Epoch  15 | Loss: 370.3629 | Train Acc: 0.8668 | Test Acc: 0.8669\n",
            "Epoch  16 | Loss: 369.5522 | Train Acc: 0.8670 | Test Acc: 0.8665\n",
            "Epoch  17 | Loss: 368.5824 | Train Acc: 0.8673 | Test Acc: 0.8668\n",
            "Epoch  18 | Loss: 368.0115 | Train Acc: 0.8675 | Test Acc: 0.8675\n",
            "Epoch  19 | Loss: 366.8230 | Train Acc: 0.8678 | Test Acc: 0.8678\n",
            "Epoch  20 | Loss: 366.1155 | Train Acc: 0.8679 | Test Acc: 0.8676\n",
            "Epoch  21 | Loss: 365.3180 | Train Acc: 0.8680 | Test Acc: 0.8682\n",
            "Epoch  22 | Loss: 364.1942 | Train Acc: 0.8682 | Test Acc: 0.8684\n",
            "Epoch  23 | Loss: 363.3242 | Train Acc: 0.8684 | Test Acc: 0.8688\n",
            "Epoch  24 | Loss: 362.5534 | Train Acc: 0.8686 | Test Acc: 0.8684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc(train_accs, test_accs)"
      ],
      "metadata": {
        "id": "td8VxMB2Macr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}